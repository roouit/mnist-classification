{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# MNIST classification with feed forward neural network\r\n",
                "In this notebook I'll build a simple neural network model with Tensorflow and Keras and use it to classify the classic MNIST dataset.\r\n",
                "\r\n",
                "---\r\n",
                "## 1. Imports and loading data\r\n",
                "The dataset is loaded from Keras API. The function `load_data()` returns the data partitioned to train and test datasets by default."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from tensorflow.keras.callbacks import TensorBoard\r\n",
                "import tensorflow as tf\r\n",
                "import numpy as np\r\n",
                "from matplotlib import pyplot as plt\r\n",
                "from datetime import datetime\r\n",
                "\r\n",
                "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\r\n",
                "## 2. Data exploration and modification\r\n",
                "From the shapes of data we see that n = 70000 and it's split to train (n = 60000) and test (n = 10000) datasets.\r\n",
                "The feature data are tensors with each single data point being a 28x28 matrix. Label data are 1D arrays."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "print(f'x_train: {x_train.shape}')\r\n",
                "print(f'y_train: {y_train.shape}')\r\n",
                "print(f'x_test: {x_test.shape}')\r\n",
                "print(f'y_test: {y_test.shape}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "x_train: (60000, 28, 28)\n",
                        "y_train: (60000,)\n",
                        "x_test: (10000, 28, 28)\n",
                        "y_test: (10000,)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "When looking at a single data point we can see that the feature matrix is a bunch of integers between 0 and 255. This is actually obvious since the features are grayscale images of digits!\r\n",
                "\r\n",
                "Labels are just simply integers telling which digit the image is representing."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "print(x_train[1])\r\n",
                "print(y_train[1])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
                        "  159  50   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
                        "  252 237   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
                        "  233 252  57   6   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
                        "   84 252 253 122   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
                        "   96 189 253 167   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
                        "   47  79 255 168   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
                        "    0   0 253 243  50   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
                        "    0   0 253 252 165   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
                        "    0   0 253 252 195   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
                        "    0   0 253 252 195   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
                        "    0   0 255 253 196   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
                        "    0   0 253 252 148   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
                        "    7 135 253 186  12   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
                        "  131 252 225  71   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
                        "  252 173   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
                        "  162   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
                        "   56   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]\n",
                        " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
                        "    0   0   0   0   0   0   0   0   0   0]]\n",
                        "0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In machine learning, and in scientific computing in general, it's important to remove any biases affecting the outcome of the model. Sometimes different numerical scales in features can lead to one feature dominating the model. This is also true for feature data fed into a neural network.\r\n",
                "\r\n",
                "The feature data is normalized here with a built-in function `normalize()`. In this case, we would've gotten the same result by dividing the data by 255. This way the feature data is normalized between 0 and 1."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "x_train = tf.keras.utils.normalize(x_train, axis=1)\r\n",
                "x_test = tf.keras.utils.normalize(x_test, axis=1)\r\n",
                "\r\n",
                "print(x_train[1])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.08216044 0.2286589  0.3728098\n",
                        "  0.30506548 0.08583808 0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.08087653 0.38341541 0.36240278 0.37133624\n",
                        "  0.48350001 0.4068725  0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.08861609 0.3824786  0.40758025 0.36240278 0.35218\n",
                        "  0.44704564 0.43262392 0.06832372 0.00859123 0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.01621743\n",
                        "  0.095788   0.36759266 0.42460179 0.40758025 0.36240278 0.29765841\n",
                        "  0.16116667 0.43262392 0.30326141 0.17468832 0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.26434406\n",
                        "  0.4023096  0.41354174 0.42460179 0.40758025 0.36240278 0.37133624\n",
                        "  0.18419048 0.32446794 0.30326141 0.23912253 0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.08411834 0.38597476\n",
                        "  0.40390606 0.41518278 0.32013627 0.18365276 0.36384089 0.33597088\n",
                        "  0.09017659 0.13562417 0.30565873 0.2405544  0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.07427511 0.39255225 0.40867916\n",
                        "  0.4023096  0.29374592 0.02021913 0.12082418 0.17401086 0.03094469\n",
                        "  0.         0.         0.30326141 0.34794476 0.12263192 0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.04890249 0.2553207  0.41729294 0.37786605\n",
                        "  0.33206506 0.13784725 0.         0.         0.         0.\n",
                        "  0.         0.         0.30326141 0.36083161 0.40468535 0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.00966301 0.22906954 0.38994434 0.39585101 0.11514373\n",
                        "  0.03033287 0.04594908 0.         0.         0.         0.\n",
                        "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.07868449 0.32430069 0.38994434 0.10391089 0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.27332506 0.3255876  0.29400565 0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.30565873 0.36226348 0.48071715 0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.33960736 0.33958568 0.32430069 0.17330859 0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.30326141 0.36083161 0.3629905  0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.37982402 0.34786826 0.29598873 0.03868495 0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.01343056 0.23176282 0.30326141 0.26632809 0.02943166 0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.37982402 0.34786826 0.28698037 0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.0103149\n",
                        "  0.25134326 0.43262392 0.26969888 0.10166287 0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.37982402 0.34786826 0.18660159 0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.0690291  0.24313682\n",
                        "  0.48350001 0.29699976 0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.38429254 0.34924869 0.28955419 0.         0.         0.\n",
                        "  0.         0.         0.         0.18365276 0.34226929 0.3728098\n",
                        "  0.31082143 0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.37982402 0.34786826 0.32043997 0.22592013 0.0791702  0.04703054\n",
                        "  0.13569967 0.29210488 0.37910874 0.40758025 0.3206977  0.24608394\n",
                        "  0.10744445 0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.37982402 0.34786826 0.32430069 0.38994434 0.37770784 0.34867468\n",
                        "  0.4023096  0.41354174 0.42460179 0.31575387 0.18695382 0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.1251185  0.27470549 0.32430069 0.38994434 0.41729294 0.40867916\n",
                        "  0.4023096  0.38236201 0.24431452 0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.03451074 0.16472416 0.38994434 0.41729294 0.40867916\n",
                        "  0.2251018  0.06071843 0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]\n",
                        " [0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.         0.         0.\n",
                        "  0.         0.         0.         0.        ]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "With default settings in pyplots `imshow()` function the grayscale digit is plotted with 'viridis' colormap. By setting the colormap to 'binary' we can see the digit plotted as black-in-white text.\r\n",
                "\r\n",
                "By printing the correct label we can verify that this is indeed a digit '0'."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "fig, axs = plt.subplots(1,2)\r\n",
                "axs[0].imshow(x_train[1])\r\n",
                "axs[1].imshow(x_train[1], cmap=plt.cm.binary)\r\n",
                "plt.show()\r\n",
                "\r\n",
                "print(f'The correct label is: {y_train[1]}')"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 2 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "The correct label is: 0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\r\n",
                "## 3. Building and fitting the model\r\n",
                "The model is very basic with no convolutions or dropouts, and only one hidden layer. \r\n",
                "\r\n",
                "The Sequential model is selected, which is a simple plain stack of single-input and single-output layers (feed forward network).\r\n",
                "\r\n",
                "### Structure of the neural network\r\n",
                "The input image gets flattened at the input layer to 784 (28x28) neurons and there is a single fully connected 256-neuron hidden layer with ReLU before the output layer. Output layer has 10 neurons, one for each digit, with softmax activation function. This outputs a probability distribution where each output value is in range(0, 1) and sum up to 1. The class with highest probability is the predicted value (digit).\r\n",
                "\r\n",
                "The chosen optimizer implements the Adam algorithm, which is based on stochastic gradient descent method.\r\n",
                "\r\n",
                "The sparse categorical crossentropy is selected as the loss function. Sparse is used because the labels aren't one-hot encoded.\r\n",
                "\r\n",
                "The sparse categorical accuracy indicates how often the predicted label matches the true label."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "NEURONS = 256\r\n",
                "EPOCHS = 10\r\n",
                "\r\n",
                "model = tf.keras.models.Sequential()\r\n",
                "model.add(tf.keras.layers.Flatten())\r\n",
                "model.add(tf.keras.layers.Dense(NEURONS, activation='relu'))\r\n",
                "model.add(tf.keras.layers.Dense(10, activation='softmax'))\r\n",
                "  \r\n",
                "model.compile(\r\n",
                "  optimizer='Adam',\r\n",
                "  loss='sparse_categorical_crossentropy',\r\n",
                "  metrics=['sparse_categorical_accuracy']\r\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Training is logged with appropriate naming to differentiate models. Tensorboard can then be used to track how loss and accuracy changes with different models.\r\n",
                "\r\n",
                "Tensorboard can be started from the command line with `tensorboard --logdir logs/fit`"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "import os\r\n",
                "\r\n",
                "log_dir = os.path.join(\r\n",
                "    \"logs\",\r\n",
                "    \"fit\",\r\n",
                "    f'FFNN-{NEURONS}-NEURONS-{EPOCHS}-EPOCHS-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\r\n",
                ")\r\n",
                "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n",
                "\r\n",
                "model.fit(\r\n",
                "  x_train,\r\n",
                "  y_train,\r\n",
                "  epochs=EPOCHS,\r\n",
                "  validation_data=(x_test, y_test),\r\n",
                "  callbacks=[tensorboard_callback]\r\n",
                ")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Train on 60000 samples, validate on 10000 samples\n",
                        "Epoch 1/10\n",
                        "60000/60000 [==============================] - 20s 336us/sample - loss: 0.2675 - sparse_categorical_accuracy: 0.9241 - val_loss: 0.1626 - val_sparse_categorical_accuracy: 0.9492\n",
                        "Epoch 2/10\n",
                        "60000/60000 [==============================] - 19s 315us/sample - loss: 0.1156 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9680\n",
                        "Epoch 3/10\n",
                        "60000/60000 [==============================] - 19s 321us/sample - loss: 0.0773 - sparse_categorical_accuracy: 0.9772 - val_loss: 0.0887 - val_sparse_categorical_accuracy: 0.9725\n",
                        "Epoch 4/10\n",
                        "60000/60000 [==============================] - 20s 341us/sample - loss: 0.0544 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0876 - val_sparse_categorical_accuracy: 0.9737\n",
                        "Epoch 5/10\n",
                        "60000/60000 [==============================] - 20s 338us/sample - loss: 0.0400 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.0772 - val_sparse_categorical_accuracy: 0.9758\n",
                        "Epoch 6/10\n",
                        "60000/60000 [==============================] - 21s 345us/sample - loss: 0.0298 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0838 - val_sparse_categorical_accuracy: 0.9758\n",
                        "Epoch 7/10\n",
                        "60000/60000 [==============================] - 19s 315us/sample - loss: 0.0222 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0742 - val_sparse_categorical_accuracy: 0.9761\n",
                        "Epoch 8/10\n",
                        "60000/60000 [==============================] - 18s 297us/sample - loss: 0.0162 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0791 - val_sparse_categorical_accuracy: 0.9771\n",
                        "Epoch 9/10\n",
                        "60000/60000 [==============================] - 20s 326us/sample - loss: 0.0121 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9755\n",
                        "Epoch 10/10\n",
                        "60000/60000 [==============================] - 20s 328us/sample - loss: 0.0098 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0964 - val_sparse_categorical_accuracy: 0.9749\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<tensorflow.python.keras.callbacks.History at 0x1b5c5eb8408>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 12
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![alt text](https://raw.githubusercontent.com/roouit/mnist-classification/master/accuracies.PNG \"Accuracies from Tensorboard\")\r\n",
                "\r\n",
                "Here are three models with 64, 128 and 256 neurons in the hidden layer trained for 10 epochs.\r\n",
                "\r\n",
                "The validation accuracies (blue and green colors) start to level off around 5 epochs, while training accuracies keep climbing (red colors) and overfitting data.\r\n",
                "\r\n",
                "The models aren't optimized at all, but the accuracies with 128 and 256 neurons get quickly over 97% even with very simple structure."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\r\n",
                "## 4. Predicting with the model\r\n",
                "A prediction gives 10 values in a range(0,1) and max value of these represents the class index, which model has predicted the digit to be.\r\n",
                "\r\n",
                "We see that this digit 7 was correctly classified by the model."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "predictions = model.predict(x_test)\r\n",
                "print(predictions[0])\r\n",
                "\r\n",
                "plt.imshow(x_test[0], cmap=plt.cm.binary)\r\n",
                "plt.show()\r\n",
                "print(f'Correct label: {y_test[0]}')\r\n",
                "print(f'Predicted label: {np.argmax(predictions[0])}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[3.0704408e-11 3.4610685e-12 5.1625626e-10 1.2732695e-06 1.7175499e-17\n",
                        " 1.1502689e-12 2.4307475e-20 9.9999869e-01 1.2917901e-09 6.2972194e-10]\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Correct label: 7\n",
                        "Predicted label: 7\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "We can also take a look at some of the misclassified digits.\r\n",
                "\r\n",
                "After visualizing few of these, it's clear that some of these would be hard for even a human being. However, this model could still be improved significantly because there are clear mistakes."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "y_pred = np.argmax(predictions, axis=1)\r\n",
                "mask = y_pred != y_test\r\n",
                "print(f'Incorrectly labelled digits: {np.count_nonzero(mask)}')\r\n",
                "\r\n",
                "incorrect_indeces = np.where(mask)\r\n",
                "fig, axs = plt.subplots(1,5,figsize=(10,6))\r\n",
                "\r\n",
                "axs[0].imshow(x_test[incorrect_indeces[0][0]], cmap=plt.cm.binary)\r\n",
                "axs[1].imshow(x_test[incorrect_indeces[0][1]], cmap=plt.cm.binary)\r\n",
                "axs[2].imshow(x_test[incorrect_indeces[0][2]], cmap=plt.cm.binary)\r\n",
                "axs[3].imshow(x_test[incorrect_indeces[0][3]], cmap=plt.cm.binary)\r\n",
                "axs[4].imshow(x_test[incorrect_indeces[0][4]], cmap=plt.cm.binary)\r\n",
                "plt.show()\r\n",
                "\r\n",
                "print(f'Correct labels: {y_test[incorrect_indeces[0][0:5]]}')\r\n",
                "print(f'Predicted label: {y_pred[incorrect_indeces[0][0:5]]}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Incorrectly labelled digits: 251\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 720x432 with 5 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Correct labels: [3 1 2 4 6]\n",
                        "Predicted label: [8 9 9 2 0]\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.10 64-bit ('DLC-CPU': conda)"
        },
        "interpreter": {
            "hash": "dccace1444a57180b98cc4958720dd912bfeeda29231ec52c5ba31f7fa94fcd5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}